{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea77bb2",
   "metadata": {},
   "source": [
    "# Explanatory Data Analysis and Preprocessing\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "In this case the data are structured as follows in order to recreate the project.\n",
    "```\n",
    ".\n",
    "├── Healthcare \n",
    "│   └── data.csv\n",
    "├── Heart_Rate_Prediction\n",
    "│   ├── Test Data\n",
    "│   │   ├── frequency_domain_features_test.csv\n",
    "│   │   ├── heart_rate_non_linear_features_test.csv\n",
    "│   │   └── time_domain_features_test.csv\n",
    "│   └── Train Data\n",
    "│       ├── frequency_domain_features_train.csv\n",
    "│       ├── heart_rate_non_linear_features_train.csv\n",
    "│       └── time_domain_features_train.csv\n",
    "├── SWELL\n",
    "│   ├── test.csv\n",
    "│   └── train.csv\n",
    "└── Stress_predict\n",
    "    ├── Questionnaires_scores.xlsx\n",
    "    ├── Time_logs.xlsx\n",
    "    └── data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850173e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hrv_calculator import compute_hrv_from_heart_rate\n",
    "\n",
    "\n",
    "# Import Data Paths\n",
    "data_path = os.getcwd() + \"/data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f56364",
   "metadata": {},
   "source": [
    "## Healthcare dataset for Nurse Stress Prediction with Wearable devices\n",
    "\n",
    "- Data Collection Context:\n",
    "    - Period: Data gathered over one week from 15 female nurses aged 30 to 55 years\n",
    "\n",
    "- Data Captured:\n",
    "    - Physiological Variables Monitored: Heart Rate of the nurse subjects.\n",
    "    - Survey Responses: Periodic smartphone-administered surveys capturing contributing factors to detected stress events.\n",
    "    - Measurement Technologies: Utilized Empatica E4 for data collection, specifically focusing on Blood Volume Pulse (BVP) readings.\n",
    "\n",
    "- Merge CSV File Information:\n",
    "    - This dataset comprises approximately 11.5 million entries across nine columns:\n",
    "    - X, Y, Z: Orientation data (256 unique entries each).\n",
    "    - EDA, HR, TEMP: Physiological measurements (EDA: 274,452 unique, HR: 6,268 unique, TEMP: 599 unique).\n",
    "    - id: 18 categorical identifiers.\n",
    "    - datetime: Extensive date and time entries (10.6 million unique).\n",
    "    - label: Categorical states or classes (three unique entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path \n",
    "health_care_path = os.path.join(data_path, \"Healthcare/data.csv\")\n",
    "nurses_pd = pd.read_csv(health_care_path)\n",
    "print(\"The initial data contains {} rows and {} columns.\".format(nurses_pd.shape[0], nurses_pd.shape[1]))\n",
    "\n",
    "# Data Preprocessing (drop unnecessary columns and convert label to int)\n",
    "data_pd = nurses_pd.drop(columns=[\"X\", \"Y\", \"Z\", \"EDA\", \"TEMP\", \"id\"])\n",
    "print(\"The data we are interested in contains {} rows and {} columns.\".format(data_pd.shape[0], data_pd.shape[1]))\n",
    "\n",
    "# Calculate time difference between consecutive samples (in seconds), drop the first NaN and calculate average time\n",
    "# Ensure the datetime column is of datetime type\n",
    "data_pd[\"datetime\"] = pd.to_datetime(data_pd[\"datetime\"])\n",
    "data_pd = data_pd.sort_values(by=\"datetime\")\n",
    "data_pd[\"time_diff\"] = data_pd[\"datetime\"].diff().dt.total_seconds()\n",
    "data_pd = data_pd.dropna(subset=[\"time_diff\"])\n",
    "average_time_diff = data_pd[\"time_diff\"].mean()\n",
    "data_pd.drop(columns=[\"time_diff\"], inplace=True)\n",
    "\n",
    "# Calculate frequency (Hz)\n",
    "sampling_frequency_hz = 1 / average_time_diff\n",
    "print(f\"Average Time Between Samples: {average_time_diff:.6f} seconds\")\n",
    "print(f\"Sampling Frequency: {sampling_frequency_hz:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf27c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to 1-second intervals using average\n",
    "data_pd.set_index('datetime', inplace=True)\n",
    "resampled_df = data_pd.resample('1S').mean(numeric_only=True)\n",
    "resampled_df = resampled_df.dropna(subset=['HR'])\n",
    "resampled_df[\"label\"] = resampled_df[\"label\"].astype(int)\n",
    "resampled_df.to_csv(os.path.join(data_path, \"Healthcare/resampled_data.csv\"), index=True)\n",
    "print(\"The data after resampling contains {} rows and {} columns.\".format(resampled_df.shape[0], resampled_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the downsampled data\n",
    "data_pd = pd.read_csv(os.path.join(data_path, \"Healthcare/resampled_data.csv\"))\n",
    "heart_rates = data_pd[\"HR\"].value_counts()\n",
    "labels = data_pd[\"label\"].value_counts()\n",
    "\n",
    "# Simple Statistical Analysis\n",
    "mean_heart_rate = data_pd[\"HR\"].mean()\n",
    "median_heart_rate = data_pd[\"HR\"].median()\n",
    "std_heart_rate = data_pd[\"HR\"].std()\n",
    "\n",
    "print(\"The mean heart rate is {:.2f} bpm.\".format(mean_heart_rate))\n",
    "print(\"The median heart rate is {:.2f} bpm.\".format(median_heart_rate))\n",
    "print(\"The standard deviation of heart rate is {:.2f} bpm.\".format(std_heart_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot statistical data for the dataset\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 8))\n",
    "\n",
    "axs[0].bar(heart_rates.index, heart_rates.values)\n",
    "axs[0].set_title(\"Heart Rate Distribution\")\n",
    "axs[0].set_xlabel(\"Heart Rate\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].bar(labels.index, labels.values)\n",
    "axs[1].set_title(\"Label Distribution\")\n",
    "axs[1].set_xlabel(\"Label\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].set_xticks(labels.index)\n",
    "axs[1].set_xticklabels(labels.index.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for HRV, calculate the difference between consecutive heart rates every 15 seconds\n",
    "step = 15\n",
    "\n",
    "# New HRV column to be filled\n",
    "hrv_values = []\n",
    "\n",
    "for i in range(0, len(data_pd), step):\n",
    "    chunk = data_pd.iloc[i:i+step]\n",
    "    if len(chunk) == step:\n",
    "        hr_list = chunk[\"HR\"].tolist()\n",
    "        ts_list = chunk[\"datetime\"].astype(str).tolist()\n",
    "        hrv_result = compute_hrv_from_heart_rate(hr_list, windowed=False, timestamps=ts_list, use_jitter=True)\n",
    "        hrv_rmssd = hrv_result[\"rmssd\"]\n",
    "        hrv_values.extend([hrv_rmssd] * 15)\n",
    "    else:\n",
    "        hrv_values.extend([np.nan] * len(chunk))\n",
    "\n",
    "# Assign to new column\n",
    "data_pd[\"HRV\"] = hrv_values\n",
    "\n",
    "# Export the data and delete downsampled data\n",
    "data_pd = data_pd[[\"HR\", \"HRV\", \"datetime\", \"label\"]]\n",
    "data_pd.to_csv(os.path.join(data_path, \"Healthcare/hrv.csv\"), index=False)\n",
    "print(\"The data with HRV contains {} rows and {} columns.\".format(data_pd.shape[0], data_pd.shape[1]))\n",
    "\n",
    "# Plot statistical data for the dataset\n",
    "hrvs = data_pd[\"HRV\"].value_counts()\n",
    "nrows = 1\n",
    "ncols = 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 8))\n",
    "\n",
    "axs.bar(hrvs.index, hrvs.values)\n",
    "axs.set_title(\"Heart Rate Variability Distribution\")\n",
    "axs.set_xlabel(\"Heart Rate Variability\")\n",
    "axs.set_ylabel(\"Frequency\")\n",
    "axs.grid()\n",
    "\n",
    "# Detete the resampled data\n",
    "os.remove(os.path.join(data_path, \"Healthcare/resampled_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4ef7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edf6ee",
   "metadata": {},
   "source": [
    "## Heart Rate Prediction to Monitor Stress Level\n",
    "The data comprises various attributes taken from signals measured using ECG recorded for different individuals having different heart rates at the time the measurement was taken. These various features contribute to the heart rate at the given instant of time for the individual.\n",
    "\n",
    "There are total of 6 CSV files with the names as follows:\n",
    "- Train:\n",
    "    - time_domain_features_train.csv - This file contains all time domain features of heart rate for training data\n",
    "    - frequency_domain_features_train.csv - This file contains all frequency domain features of heart rate for training data\n",
    "    - heart_rate_non_linear_features_train.csv - This file contains all non linear features of heart rate for training data\n",
    "\n",
    "- Test: \n",
    "    - time_domain_features_test.csv - This file contains all time domain features of heart rate for testing data\n",
    "    - frequency_domain_features_test.csv - This file contains all frequency domain features of heart rate for testing data\n",
    "    - heart_rate_non_linear_features_test.csv - This file contains all non linear features of heart rate for testing data\n",
    "\n",
    "Following is the data dictionary for the features you will come across in the files mentioned:\n",
    "- MEAN_RR - Mean of RR intervals\n",
    "- MEDIAN_RR - Median of RR intervals\n",
    "- SDRR - Standard deviation of RR intervals\n",
    "- **RMSSD - Root mean square of successive RR interval differences**\n",
    "- SDSD - Standard deviation of successive RR interval differences\n",
    "- SDRR_RMSSD - Ratio of SDRR / RMSSD\n",
    "- pNN25 - Percentage of successive RR intervals that differ by more than 25 ms\n",
    "- pNN50 - Percentage of successive RR intervals that differ by more than 50 ms\n",
    "- KURT - Kurtosis of distribution of successive RR intervals\n",
    "- SKEW - Skew of distribution of successive RR intervals\n",
    "- MEAN_REL_RR - Mean of relative RR intervals\n",
    "- MEDIAN_REL_RR - Median of relative RR intervals\n",
    "- SDRR_REL_RR - Standard deviation of relative RR intervals\n",
    "- RMSSD_REL_RR - Root mean square of successive relative RR interval differences\n",
    "- SDSD_REL_RR - Standard deviation of successive relative RR interval differences\n",
    "- SDRR_RMSSD_REL_RR - Ratio of SDRR/RMSSD for relative RR interval differences\n",
    "- KURT_REL_RR - Kurtosis of distribution of relative RR intervals\n",
    "- SKEW_REL_RR - Skewness of distribution of relative RR intervals\n",
    "- **uuid - Unique ID for each patient**\n",
    "- VLF - Absolute power of the very low frequency band (0.0033 - 0.04 Hz)\n",
    "- VLF_PCT - Principal component transform of VLF\n",
    "- LF - Absolute power of the low frequency band (0.04 - 0.15 Hz)\n",
    "- LF_PCT - Principal component transform of LF\n",
    "- LF_NU - Absolute power of the low frequency band in normal units\n",
    "- HF - Absolute power of the high frequency band (0.15 - 0.4 Hz)\n",
    "- HF_PCT - Principal component transform of HF\n",
    "- HF_NU - Absolute power of the highest frequency band in normal units\n",
    "- TP - Total power of RR intervals\n",
    "- LF_HF - Ratio of LF to HF\n",
    "- HF_LF - Ratio of HF to LF\n",
    "- SD1 - Poincaré plot standard deviation perpendicular to the line of identity\n",
    "- SD2 - Poincaré plot standard deviation along the line of identity\n",
    "- Sampen - sample entropy which measures the regularity and complexity of a time series\n",
    "- higuci - higuci fractal dimension of heartrate\n",
    "- datasetId - ID of the whole dataset\n",
    "- **condition - condition of the patient at the time the data was recorded**\n",
    "- **HR - Heart rate of the patient at the time of data recorded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e93f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path \n",
    "train_non_linear_path  = os.path.join(data_path,  \"Heart_Rate_Prediction/Train_Data/hr_non_linear.csv\")\n",
    "train_time_domain_path = os.path.join(data_path, \"Heart_Rate_Prediction/Train_Data/hr_time_domain.csv\")\n",
    "\n",
    "test_non_linear_path  = os.path.join(data_path,  \"Heart_Rate_Prediction/Test_Data/hr_non_linear.csv\")\n",
    "test_time_domain_path = os.path.join(data_path, \"Heart_Rate_Prediction/Test_Data/hr_time_domain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial non linear data contains 369289 rows and 7 columns.\n",
      "The initial time domain data contains 369289 rows and 20 columns.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uuid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSSD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b7d3c978-6d29-47a4-b076-d52402c7d57c",
       "rows": [
        [
         "0",
         "89df2855-56eb-4706-a23b-b39363dd605a",
         "no stress",
         "15.55450455844723",
         "69.49995211314423"
        ],
        [
         "1",
         "80c795e4-aa56-4cc0-939c-19634b89cbb2",
         "interruption",
         "12.964439460159",
         "64.36314993344149"
        ],
        [
         "2",
         "c2d5d102-967c-487d-88f2-8b005a449f3e",
         "interruption",
         "16.30527866953465",
         "67.45006558887458"
        ],
        [
         "3",
         "37eabc44-1349-4040-8896-0d113ad4811f",
         "no stress",
         "15.72046848681109",
         "68.80956180311732"
        ],
        [
         "4",
         "aa777a6a-7aa3-4f6e-aced-70f8691dd2b7",
         "no stress",
         "19.21381886895778",
         "74.56572751929652"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>condition</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89df2855-56eb-4706-a23b-b39363dd605a</td>\n",
       "      <td>no stress</td>\n",
       "      <td>15.554505</td>\n",
       "      <td>69.499952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80c795e4-aa56-4cc0-939c-19634b89cbb2</td>\n",
       "      <td>interruption</td>\n",
       "      <td>12.964439</td>\n",
       "      <td>64.363150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c2d5d102-967c-487d-88f2-8b005a449f3e</td>\n",
       "      <td>interruption</td>\n",
       "      <td>16.305279</td>\n",
       "      <td>67.450066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37eabc44-1349-4040-8896-0d113ad4811f</td>\n",
       "      <td>no stress</td>\n",
       "      <td>15.720468</td>\n",
       "      <td>68.809562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa777a6a-7aa3-4f6e-aced-70f8691dd2b7</td>\n",
       "      <td>no stress</td>\n",
       "      <td>19.213819</td>\n",
       "      <td>74.565728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid     condition      RMSSD         HR\n",
       "0  89df2855-56eb-4706-a23b-b39363dd605a     no stress  15.554505  69.499952\n",
       "1  80c795e4-aa56-4cc0-939c-19634b89cbb2  interruption  12.964439  64.363150\n",
       "2  c2d5d102-967c-487d-88f2-8b005a449f3e  interruption  16.305279  67.450066\n",
       "3  37eabc44-1349-4040-8896-0d113ad4811f     no stress  15.720468  68.809562\n",
       "4  aa777a6a-7aa3-4f6e-aced-70f8691dd2b7     no stress  19.213819  74.565728"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data pipeline\n",
    "train_non_linear_df  = pd.read_csv(train_non_linear_path)\n",
    "train_time_domain_df = pd.read_csv(train_time_domain_path)\n",
    "print(\"The initial non linear  train data contains {} rows and {} columns.\".format(train_non_linear_df.shape[0], train_non_linear_df.shape[1]))\n",
    "print(\"The initial time domain train data contains {} rows and {} columns.\".format(train_time_domain_df.shape[0], train_time_domain_df.shape[1]))\n",
    "\n",
    "# Drop unnecessary columns and join the data in one new dataframe\n",
    "train_non_linear_df = train_non_linear_df.drop(columns=[\"SD1\", \"SD2\", \"sampen\", \"higuci\", \"datasetId\"], axis=1)\n",
    "\n",
    "columns_to_drop = [\"MEAN_RR\",\"MEDIAN_RR\",\"SDRR\",\"SDSD\",\"SDRR_RMSSD\",\"pNN25\",\"pNN50\",\"KURT\",\"SKEW\",\"MEAN_REL_RR\",\"MEDIAN_REL_RR\",\"SDRR_REL_RR\",\n",
    "                  \"RMSSD_REL_RR\",\"SDSD_REL_RR\",\"SDRR_RMSSD_REL_RR\",\"KURT_REL_RR\",\"SKEW_REL_RR\"]\n",
    "train_time_domain_df = train_time_domain_df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "# Merge the two dataframes\n",
    "train_data = pd.merge(train_non_linear_df, train_time_domain_df, on=[\"uuid\"], how=\"inner\")\n",
    "print(\"The merged train data contains {} rows and {} columns.\".format(train_data.shape[0], train_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3d9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean heart rate is 73.94 bpm.\n",
      "The median heart rate is 74.22 bpm.\n",
      "The standard deviation of heart rate is 10.34 bpm.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m ncols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     18\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows, ncols, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheart_rates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheart_rates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeart Rate Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeart Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/__init__.py:1414\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1417\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1418\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2412\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   2411\u001b[0m         r\u001b[38;5;241m.\u001b[39msticky_edges\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mappend(l)\n\u001b[0;32m-> 2412\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2413\u001b[0m     patches\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/axes/_base.py:2363\u001b[0m, in \u001b[0;36m_AxesBase.add_patch\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2362\u001b[0m     p\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 2363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_patch_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m   2365\u001b[0m p\u001b[38;5;241m.\u001b[39m_remove_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mremove\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/axes/_base.py:2397\u001b[0m, in \u001b[0;36m_AxesBase._update_patch_limits\u001b[0;34m(self, patch)\u001b[0m\n\u001b[1;32m   2395\u001b[0m         updatey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m trf_to_data \u001b[38;5;241m=\u001b[39m patch_trf \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransData\n\u001b[0;32m-> 2397\u001b[0m xys \u001b[38;5;241m=\u001b[39m \u001b[43mtrf_to_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvertices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_datalim(xys, updatex\u001b[38;5;241m=\u001b[39mupdatex, updatey\u001b[38;5;241m=\u001b[39mupdatey)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/transforms.py:1503\u001b[0m, in \u001b[0;36mTransform.transform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1500\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dims))\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Transform the values\u001b[39;00m\n\u001b[0;32m-> 1503\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_non_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/transforms.py:2419\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_affine\u001b[39m(\u001b[38;5;28mself\u001b[39m, points):\n\u001b[1;32m   2418\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m-> 2419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(points)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/transforms.py:2447\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\u001b[38;5;241m.\u001b[39mget_matrix(),\n\u001b[0;32m-> 2447\u001b[0m                            \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/transforms.py:2606\u001b[0m, in \u001b[0;36mBboxTransformTo.get_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalid:\n\u001b[1;32m   2605\u001b[0m     outl, outb, outw, outh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boxout\u001b[38;5;241m.\u001b[39mbounds\n\u001b[0;32m-> 2606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG \u001b[38;5;129;01mand\u001b[39;00m (outw \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m outh \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   2607\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransforming to a singular bounding box.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[outw,  \u001b[38;5;241m0.0\u001b[39m, outl],\n\u001b[1;32m   2609\u001b[0m                           [ \u001b[38;5;241m0.0\u001b[39m, outh, outb],\n\u001b[1;32m   2610\u001b[0m                           [ \u001b[38;5;241m0.0\u001b[39m,  \u001b[38;5;241m0.0\u001b[39m,  \u001b[38;5;241m1.0\u001b[39m]],\n\u001b[1;32m   2611\u001b[0m                          \u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "heart_rates = train_data[\"HR\"].value_counts()\n",
    "labels = train_data[\"condition\"].value_counts()\n",
    "\n",
    "# Simple Statistical Analysis\n",
    "mean_heart_rate = train_data[\"HR\"].mean()\n",
    "median_heart_rate = train_data[\"HR\"].median()\n",
    "std_heart_rate = train_data[\"HR\"].std()\n",
    "\n",
    "print(\"The mean heart rate is {:.2f} bpm.\".format(mean_heart_rate))\n",
    "print(\"The median heart rate is {:.2f} bpm.\".format(median_heart_rate))\n",
    "print(\"The standard deviation of heart rate is {:.2f} bpm.\".format(std_heart_rate))\n",
    "\n",
    "\n",
    "# Plot statistical data for the dataset\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 8))\n",
    "\n",
    "axs[0].bar(heart_rates.index, heart_rates.values)\n",
    "axs[0].set_title(\"Heart Rate Distribution\")\n",
    "axs[0].set_xlabel(\"Heart Rate\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].bar(labels.index, labels.values)\n",
    "axs[1].set_title(\"Label Distribution\")\n",
    "axs[1].set_xlabel(\"Label\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].set_xticks(labels.index)\n",
    "axs[1].set_xticklabels(labels.index.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12493bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial non linear  test data contains 41033 rows and 7 columns.\n",
      "The initial time domain test data contains 41033 rows and 19 columns.\n",
      "The merged train data contains 369289 rows and 4 columns.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uuid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSSD",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5f4db6d7-0947-4c23-9111-8f9df79abdb9",
       "rows": [
        [
         "0",
         "62b75db5-bc40-4c8f-9166-daf0efcab4c2",
         "time pressure",
         "11.801781275114829"
        ],
        [
         "1",
         "a99549ad-3eb6-4413-bc90-9053e7f7e684",
         "no stress",
         "20.55881020944057"
        ],
        [
         "2",
         "cb573d3a-c767-4556-b32e-ad8c08ded214",
         "no stress",
         "13.853736610296233"
        ],
        [
         "3",
         "47a0c6de-2aef-4ac3-997d-252fa6fd07f1",
         "time pressure",
         "16.45719390807425"
        ],
        [
         "4",
         "de3fd54f-c74e-4fe8-bf2a-7a127f68b312",
         "interruption",
         "10.273113575101233"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>condition</th>\n",
       "      <th>RMSSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62b75db5-bc40-4c8f-9166-daf0efcab4c2</td>\n",
       "      <td>time pressure</td>\n",
       "      <td>11.801781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a99549ad-3eb6-4413-bc90-9053e7f7e684</td>\n",
       "      <td>no stress</td>\n",
       "      <td>20.558810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb573d3a-c767-4556-b32e-ad8c08ded214</td>\n",
       "      <td>no stress</td>\n",
       "      <td>13.853737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47a0c6de-2aef-4ac3-997d-252fa6fd07f1</td>\n",
       "      <td>time pressure</td>\n",
       "      <td>16.457194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de3fd54f-c74e-4fe8-bf2a-7a127f68b312</td>\n",
       "      <td>interruption</td>\n",
       "      <td>10.273114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid      condition      RMSSD\n",
       "0  62b75db5-bc40-4c8f-9166-daf0efcab4c2  time pressure  11.801781\n",
       "1  a99549ad-3eb6-4413-bc90-9053e7f7e684      no stress  20.558810\n",
       "2  cb573d3a-c767-4556-b32e-ad8c08ded214      no stress  13.853737\n",
       "3  47a0c6de-2aef-4ac3-997d-252fa6fd07f1  time pressure  16.457194\n",
       "4  de3fd54f-c74e-4fe8-bf2a-7a127f68b312   interruption  10.273114"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data pipeline\n",
    "test_non_linear_df  = pd.read_csv(test_non_linear_path)\n",
    "test_time_domain_df = pd.read_csv(test_time_domain_path)\n",
    "print(\"The initial non linear  test data contains {} rows and {} columns.\".format(test_non_linear_df.shape[0], test_non_linear_df.shape[1]))\n",
    "print(\"The initial time domain test data contains {} rows and {} columns.\".format(test_time_domain_df.shape[0], test_time_domain_df.shape[1]))\n",
    "\n",
    "# Drop unnecessary columns and join the data in one new dataframe\n",
    "test_non_linear_df = test_non_linear_df.drop(columns=[\"SD1\", \"SD2\", \"sampen\", \"higuci\", \"datasetId\"], axis=1)\n",
    "\n",
    "columns_to_drop = [\"MEAN_RR\",\"MEDIAN_RR\",\"SDRR\",\"SDSD\",\"SDRR_RMSSD\",\"pNN25\",\"pNN50\",\"KURT\",\"SKEW\",\"MEAN_REL_RR\",\"MEDIAN_REL_RR\",\"SDRR_REL_RR\",\n",
    "                  \"RMSSD_REL_RR\",\"SDSD_REL_RR\",\"SDRR_RMSSD_REL_RR\",\"KURT_REL_RR\",\"SKEW_REL_RR\"]\n",
    "test_time_domain_df = test_time_domain_df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "# Merge the two dataframes\n",
    "test_data = pd.merge(test_non_linear_df, test_time_domain_df, on=[\"uuid\"], how=\"inner\")\n",
    "print(\"The merged train data contains {} rows and {} columns.\".format(train_data.shape[0], train_data.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
