{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea77bb2",
   "metadata": {},
   "source": [
    "# Explanatory Data Analysis and Preprocessing\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "In this case the data are structured as follows in order to recreate the project.\n",
    "```\n",
    ".\n",
    "├── Healthcare \n",
    "│   └── data.csv\n",
    "├── Heart_Rate_Prediction\n",
    "│   ├── Test Data\n",
    "│   │   ├── frequency_domain_features_test.csv\n",
    "│   │   ├── heart_rate_non_linear_features_test.csv\n",
    "│   │   └── time_domain_features_test.csv\n",
    "│   └── Train Data\n",
    "│       ├── frequency_domain_features_train.csv\n",
    "│       ├── heart_rate_non_linear_features_train.csv\n",
    "│       └── time_domain_features_train.csv\n",
    "├── SWELL\n",
    "│   ├── test.csv\n",
    "│   └── train.csv\n",
    "└── Stress_predict\n",
    "    ├── Questionnaires_scores.xlsx\n",
    "    ├── Time_logs.xlsx\n",
    "    └── data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850173e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hrv_calculator import compute_hrv_from_heart_rate\n",
    "\n",
    "\n",
    "# Import Data Paths\n",
    "data_path = os.getcwd() + \"/data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f56364",
   "metadata": {},
   "source": [
    "## Healthcare dataset for Nurse Stress Prediction with Wearable devices\n",
    "\n",
    "- Data Collection Context:\n",
    "    - Period: Data gathered over one week from 15 female nurses aged 30 to 55 years\n",
    "\n",
    "- Data Captured:\n",
    "    - Physiological Variables Monitored: Heart Rate of the nurse subjects.\n",
    "    - Survey Responses: Periodic smartphone-administered surveys capturing contributing factors to detected stress events.\n",
    "    - Measurement Technologies: Utilized Empatica E4 for data collection, specifically focusing on Blood Volume Pulse (BVP) readings.\n",
    "\n",
    "- Merge CSV File Information:\n",
    "    - This dataset comprises approximately 11.5 million entries across nine columns:\n",
    "    - X, Y, Z: Orientation data (256 unique entries each).\n",
    "    - EDA, HR, TEMP: Physiological measurements (EDA: 274,452 unique, HR: 6,268 unique, TEMP: 599 unique).\n",
    "    - id: 18 categorical identifiers.\n",
    "    - datetime: Extensive date and time entries (10.6 million unique).\n",
    "    - label: Categorical states or classes (three unique entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path \n",
    "health_care_path = os.path.join(data_path, \"Healthcare/data.csv\")\n",
    "nurses_pd = pd.read_csv(health_care_path)\n",
    "print(\"The initial data contains {} rows and {} columns.\".format(nurses_pd.shape[0], nurses_pd.shape[1]))\n",
    "\n",
    "# Data Preprocessing (drop unnecessary columns and convert label to int)\n",
    "data_pd = nurses_pd.drop(columns=[\"X\", \"Y\", \"Z\", \"EDA\", \"TEMP\", \"id\"])\n",
    "print(\"The data we are interested in contains {} rows and {} columns.\".format(data_pd.shape[0], data_pd.shape[1]))\n",
    "\n",
    "# Calculate time difference between consecutive samples (in seconds), drop the first NaN and calculate average time\n",
    "# Ensure the datetime column is of datetime type\n",
    "data_pd[\"datetime\"] = pd.to_datetime(data_pd[\"datetime\"])\n",
    "data_pd = data_pd.sort_values(by=\"datetime\")\n",
    "data_pd[\"time_diff\"] = data_pd[\"datetime\"].diff().dt.total_seconds()\n",
    "data_pd = data_pd.dropna(subset=[\"time_diff\"])\n",
    "average_time_diff = data_pd[\"time_diff\"].mean()\n",
    "data_pd.drop(columns=[\"time_diff\"], inplace=True)\n",
    "\n",
    "# Calculate frequency (Hz)\n",
    "sampling_frequency_hz = 1 / average_time_diff\n",
    "print(f\"Average Time Between Samples: {average_time_diff:.6f} seconds\")\n",
    "print(f\"Sampling Frequency: {sampling_frequency_hz:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf27c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to 1-second intervals using average\n",
    "data_pd.set_index('datetime', inplace=True)\n",
    "resampled_df = data_pd.resample('1S').mean(numeric_only=True)\n",
    "resampled_df = resampled_df.dropna(subset=['HR'])\n",
    "resampled_df[\"label\"] = resampled_df[\"label\"].astype(int)\n",
    "resampled_df.to_csv(os.path.join(data_path, \"Healthcare/resampled_data.csv\"), index=True)\n",
    "print(\"The data after resampling contains {} rows and {} columns.\".format(resampled_df.shape[0], resampled_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the downsampled data\n",
    "data_pd = pd.read_csv(os.path.join(data_path, \"Healthcare/resampled_data.csv\"))\n",
    "heart_rates = data_pd[\"HR\"].value_counts()\n",
    "labels = data_pd[\"label\"].value_counts()\n",
    "\n",
    "# Simple Statistical Analysis\n",
    "mean_heart_rate = data_pd[\"HR\"].mean()\n",
    "median_heart_rate = data_pd[\"HR\"].median()\n",
    "std_heart_rate = data_pd[\"HR\"].std()\n",
    "\n",
    "print(\"The mean heart rate is {:.2f} bpm.\".format(mean_heart_rate))\n",
    "print(\"The median heart rate is {:.2f} bpm.\".format(median_heart_rate))\n",
    "print(\"The standard deviation of heart rate is {:.2f} bpm.\".format(std_heart_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot statistical data for the dataset\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 8))\n",
    "\n",
    "axs[0].bar(heart_rates.index, heart_rates.values)\n",
    "axs[0].set_title(\"Heart Rate Distribution\")\n",
    "axs[0].set_xlabel(\"Heart Rate\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].bar(labels.index, labels.values)\n",
    "axs[1].set_title(\"Label Distribution\")\n",
    "axs[1].set_xlabel(\"Label\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].set_xticks(labels.index)\n",
    "axs[1].set_xticklabels(labels.index.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for HRV, calculate the difference between consecutive heart rates every 15 seconds\n",
    "step = 15\n",
    "\n",
    "# New HRV column to be filled\n",
    "hrv_values = []\n",
    "\n",
    "for i in range(0, len(data_pd), step):\n",
    "    chunk = data_pd.iloc[i:i+step]\n",
    "    if len(chunk) == step:\n",
    "        hr_list = chunk[\"HR\"].tolist()\n",
    "        ts_list = chunk[\"datetime\"].astype(str).tolist()\n",
    "        hrv_result = compute_hrv_from_heart_rate(hr_list, windowed=False, timestamps=ts_list, use_jitter=True)\n",
    "        hrv_rmssd = hrv_result[\"rmssd\"]\n",
    "        hrv_values.extend([hrv_rmssd] * 15)\n",
    "    else:\n",
    "        hrv_values.extend([np.nan] * len(chunk))\n",
    "\n",
    "# Assign to new column\n",
    "data_pd[\"HRV\"] = hrv_values\n",
    "\n",
    "# Export the data and delete downsampled data\n",
    "data_pd = data_pd[[\"HR\", \"HRV\", \"datetime\", \"label\"]]\n",
    "data_pd.to_csv(os.path.join(data_path, \"Healthcare/hrv.csv\"), index=False)\n",
    "print(\"The data with HRV contains {} rows and {} columns.\".format(data_pd.shape[0], data_pd.shape[1]))\n",
    "\n",
    "# Plot statistical data for the dataset\n",
    "hrvs = data_pd[\"HRV\"].value_counts()\n",
    "nrows = 1\n",
    "ncols = 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 8))\n",
    "\n",
    "axs.bar(hrvs.index, hrvs.values)\n",
    "axs.set_title(\"Heart Rate Variability Distribution\")\n",
    "axs.set_xlabel(\"Heart Rate Variability\")\n",
    "axs.set_ylabel(\"Frequency\")\n",
    "axs.grid()\n",
    "\n",
    "# Detete the resampled data\n",
    "os.remove(os.path.join(data_path, \"Healthcare/resampled_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4ef7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edf6ee",
   "metadata": {},
   "source": [
    "## Heart Rate Prediction to Monitor Stress Level\n",
    "The data comprises various attributes taken from signals measured using ECG recorded for different individuals having different heart rates at the time the measurement was taken. These various features contribute to the heart rate at the given instant of time for the individual.\n",
    "\n",
    "There are total of 6 CSV files with the names as follows:\n",
    "- Train:\n",
    "    - time_domain_features_train.csv - This file contains all time domain features of heart rate for training data\n",
    "    - frequency_domain_features_train.csv - This file contains all frequency domain features of heart rate for training data\n",
    "    - heart_rate_non_linear_features_train.csv - This file contains all non linear features of heart rate for training data\n",
    "\n",
    "- Test: \n",
    "    - time_domain_features_test.csv - This file contains all time domain features of heart rate for testing data\n",
    "    - frequency_domain_features_test.csv - This file contains all frequency domain features of heart rate for testing data\n",
    "    - heart_rate_non_linear_features_test.csv - This file contains all non linear features of heart rate for testing data\n",
    "\n",
    "Following is the data dictionary for the features you will come across in the files mentioned:\n",
    "- MEAN_RR - Mean of RR intervals\n",
    "- MEDIAN_RR - Median of RR intervals\n",
    "- SDRR - Standard deviation of RR intervals\n",
    "- **RMSSD - Root mean square of successive RR interval differences**\n",
    "- SDSD - Standard deviation of successive RR interval differences\n",
    "- SDRR_RMSSD - Ratio of SDRR / RMSSD\n",
    "- pNN25 - Percentage of successive RR intervals that differ by more than 25 ms\n",
    "- pNN50 - Percentage of successive RR intervals that differ by more than 50 ms\n",
    "- KURT - Kurtosis of distribution of successive RR intervals\n",
    "- SKEW - Skew of distribution of successive RR intervals\n",
    "- MEAN_REL_RR - Mean of relative RR intervals\n",
    "- MEDIAN_REL_RR - Median of relative RR intervals\n",
    "- SDRR_REL_RR - Standard deviation of relative RR intervals\n",
    "- RMSSD_REL_RR - Root mean square of successive relative RR interval differences\n",
    "- SDSD_REL_RR - Standard deviation of successive relative RR interval differences\n",
    "- SDRR_RMSSD_REL_RR - Ratio of SDRR/RMSSD for relative RR interval differences\n",
    "- KURT_REL_RR - Kurtosis of distribution of relative RR intervals\n",
    "- SKEW_REL_RR - Skewness of distribution of relative RR intervals\n",
    "- **uuid - Unique ID for each patient**\n",
    "- VLF - Absolute power of the very low frequency band (0.0033 - 0.04 Hz)\n",
    "- VLF_PCT - Principal component transform of VLF\n",
    "- LF - Absolute power of the low frequency band (0.04 - 0.15 Hz)\n",
    "- LF_PCT - Principal component transform of LF\n",
    "- LF_NU - Absolute power of the low frequency band in normal units\n",
    "- HF - Absolute power of the high frequency band (0.15 - 0.4 Hz)\n",
    "- HF_PCT - Principal component transform of HF\n",
    "- HF_NU - Absolute power of the highest frequency band in normal units\n",
    "- TP - Total power of RR intervals\n",
    "- LF_HF - Ratio of LF to HF\n",
    "- HF_LF - Ratio of HF to LF\n",
    "- SD1 - Poincaré plot standard deviation perpendicular to the line of identity\n",
    "- SD2 - Poincaré plot standard deviation along the line of identity\n",
    "- Sampen - sample entropy which measures the regularity and complexity of a time series\n",
    "- higuci - higuci fractal dimension of heartrate\n",
    "- datasetId - ID of the whole dataset\n",
    "- **condition - condition of the patient at the time the data was recorded**\n",
    "- **HR - Heart rate of the patient at the time of data recorded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e93f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path \n",
    "train_non_linear = os.path.join(data_path,  \"Heart_Rate_Prediction/Train_Data/hr_non_linear.csv\")\n",
    "train_time_domain = os.path.join(data_path, \"Heart_Rate_Prediction/Train_Data/hr_time_domain.csv\")\n",
    "\n",
    "test_non_linear = os.path.join(data_path,  \"Heart_Rate_Prediction/Test_Data/hr_non_linear.csv\")\n",
    "test_time_domain = os.path.join(data_path, \"Heart_Rate_Prediction/Test_Data/hr_time_domain.csv\")\n",
    "\n",
    "nurses_pd = pd.read_csv(health_care_path)\n",
    "print(\"The initial data contains {} rows and {} columns.\".format(nurses_pd.shape[0], nurses_pd.shape[1]))\n",
    "\n",
    "# Data Preprocessing (drop unnecessary columns and convert label to int)\n",
    "data_pd = nurses_pd.drop(columns=[\"X\", \"Y\", \"Z\", \"EDA\", \"TEMP\", \"id\"])\n",
    "print(\"The data we are interested in contains {} rows and {} columns.\".format(data_pd.shape[0], data_pd.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
