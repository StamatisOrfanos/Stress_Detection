{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c29179",
   "metadata": {},
   "source": [
    "# Stress Detection Models \n",
    "\n",
    "In this notebook we are going to be testing three approaches for stress detection using biosignals like Heart Rate and/or Heart Rate Variability for each one of the following datasets:\n",
    "\n",
    "1. [Nurse Stress Prediction Wearable Sensors](https://www.kaggle.com/datasets/priyankraval/nurse-stress-prediction-wearable-sensors)\n",
    "2. [Heart Rate Prediction to Monitor Stress Level](https://www.kaggle.com/datasets/vinayakshanawad/heart-rate-prediction-to-monitor-stress-level)\n",
    "3. [Stress-Predict-Dataset](https://github.com/italha-d/Stress-Predict-Dataset)\n",
    "4. [SWELL dataset](https://www.kaggle.com/datasets/qiriro/swell-heart-rate-variability-hrv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras import Input\n",
    "\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# Import Data Paths\n",
    "data_path = os.getcwd() + '/data' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bda21d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d7f91",
   "metadata": {},
   "source": [
    "# Nurse Stress Prediction Wearable Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21805c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(data_path + '/Healthcare/hrv.csv')\n",
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed762a",
   "metadata": {},
   "source": [
    "## Threshold-Based Rule Engine Approach\n",
    "\n",
    "+ Pros:\n",
    "    - Easy to understand and deploy\n",
    "    - No training needed\n",
    "\n",
    "- Cons:\n",
    "    - May be inaccurate\n",
    "    - Doesnâ€™t adapt to individual differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stress_threshold(hrv: float, hr: float) -> str:\n",
    "    if hrv < 40 and hr > 70:\n",
    "        return 'high'\n",
    "    elif hrv < 50 and hr > 60:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions of the rule-based model and encode the labels to get the accuracy of this approach\n",
    "data['stress_pred_rule'] = data.apply(lambda row: classify_stress_threshold(row['HRV'], row['HR']), axis=1)\n",
    "labels = data['label'].apply(lambda x: 'high' if x == 2 else ('medium' if x == 1 else 'low'))\n",
    "labels_predictions = data['stress_pred_rule']\n",
    "\n",
    "print('Threshold-Based Rule Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the threshold-based rule is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c5dca",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Approach (Clustering)\n",
    "\n",
    "- Pros:\n",
    "    - No labels needed\n",
    "    - Can reveal natural structure\n",
    "\n",
    "- Cons:\n",
    "    - Clusters may not match stress labels\n",
    "    - Hard to evaluate accuracy directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208aa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kmeans model with 3 clusters for the 3 classes [low, medium, high]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(data[['HRV', 'HR']])\n",
    "data['stress_pred_kmeans'] = kmeans.predict(data[['HRV', 'HR']])\n",
    "\n",
    "# Map the cluster labels to the stress levels\n",
    "cluster_mapping = {0: 'low', 1: 'medium', 2: 'high'}\n",
    "data['stress_pred_kmeans'] = data['stress_pred_kmeans'].map(cluster_mapping)\n",
    "\n",
    "# Get the predictions of the Kmeans model and encode the labels to get the accuracy of this approach\n",
    "labels_predictions = data['stress_pred_kmeans']\n",
    "print('Kmeans Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the Kmeans model is:\\n', classification_report(labels, labels_predictions, zero_division=0))\n",
    "\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Kmeans Clusters')\n",
    "plt.scatter(data['HR'], data['HRV'], c=data['stress_pred_kmeans'].map({'low': 0, 'medium': 1, 'high': 2}), s=5)\n",
    "plt.xlabel('HR')\n",
    "plt.ylabel('HRV')\n",
    "plt.colorbar(ticks=[0, 1, 2], label='Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072c981",
   "metadata": {},
   "source": [
    "## Machine Learning Approach (Random Forest)\n",
    "\n",
    "- Pros:\n",
    "    - Learns patterns from data\n",
    "    - Easy to extend with more features\n",
    "\n",
    "- Cons:\n",
    "    - Requires labeled data\n",
    "    - Risk of overfitting on small or biased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features and labels for the Random Forest Classifier\n",
    "X = data[['HR', 'HRV']]\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create the Random Forest Classifier model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions of the Random Forest Classifier\n",
    "data['stress_pred_rf'] = clf.predict(X)\n",
    "data['stress_pred_rf'] = data['stress_pred_rf'].map({0: 'low', 1: 'medium', 2: 'high'})\n",
    "labels_predictions = data['stress_pred_rf']\n",
    "\n",
    "\n",
    "print('The classification report matrix of the train data for the Random Forest Classifier is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56290d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions of the Random Forest Classifier and encode the labels to get the accuracy of this approach\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Encode the labels to present the accuracy of this approach for the test data\n",
    "y_test = y_test.map({0: 'low', 1: 'medium', 2: 'high'})\n",
    "y_pred = pd.Series(y_pred).map({0: 'low', 1: 'medium', 2: 'high'})\n",
    "\n",
    "print('The classification report matrix of the test data for the Random Forest Classifier is:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67166f94",
   "metadata": {},
   "source": [
    "## Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering and Scaling\n",
    "features = data[['HR', 'HRV']]\n",
    "labels = data['label'].astype('int32')\n",
    "\n",
    "# Create the train/test split\n",
    "features_train, features_test, labels_train, labels_test= train_test_split(features, labels, test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa85ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function for early stopping in case we have a decrease in accuracy\n",
    "callback = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=True, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# Create the Deep Learning Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(features_train.shape[1],)))\n",
    "model.add(Dense(features_train.shape[1], activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history=model.fit(features_train, labels_train, validation_split=0.1, epochs=10, verbose=True, batch_size=512, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e16134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traininng Visualization\n",
    "plt.plot(history.history['val_accuracy'],color='red',label='Validation')\n",
    "plt.plot(history.history['accuracy'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Traininng Visualization\n",
    "plt.plot(history.history['val_loss'],color='red',label='Validation')\n",
    "plt.plot(history.history['loss'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e26f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on Testing Data\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b4db6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b6e063",
   "metadata": {},
   "source": [
    "# Heart Rate Prediction to Monitor Stress Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bff008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_data = pd.read_csv(data_path + '/Heart_Rate_Prediction/Train_Data/train.csv')\n",
    "train_data = train_data.rename(columns={'RMSSD': 'HRV'})\n",
    "train_data.dropna(inplace=True)\n",
    "\n",
    "# Map the stress levels to the labels [high, medium, low]\n",
    "train_data['condition'] = train_data['condition'].map({'no stress': 'low', 'interruption': 'medium', 'time pressure': 'high'})\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51595fb1",
   "metadata": {},
   "source": [
    "## Threshold-Based Rule Engine Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions of the rule-based model and encode the labels to get the accuracy of this approach\n",
    "train_data['stress_pred_rule'] = train_data.apply(lambda row: classify_stress_threshold(row['HRV'], row['HR']), axis=1)\n",
    "labels = train_data['condition']\n",
    "labels_predictions = train_data['stress_pred_rule']\n",
    "\n",
    "\n",
    "print('Threshold-Based Rule Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the threshold-based rule is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9faa7",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Approach (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kmeans model with 3 clusters for the 3 classes [low, medium, high]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(train_data[['HRV', 'HR']])\n",
    "train_data['stress_pred_kmeans'] = kmeans.predict(train_data[['HRV', 'HR']])\n",
    "\n",
    "# Map the cluster labels to the stress levels\n",
    "cluster_mapping = {0: 'low', 1: 'medium', 2: 'high'}\n",
    "train_data['stress_pred_kmeans'] = train_data['stress_pred_kmeans'].map(cluster_mapping)\n",
    "\n",
    "# Get the predictions of the Kmeans model and encode the labels to get the accuracy of this approach\n",
    "labels_predictions = train_data['stress_pred_kmeans']\n",
    "\n",
    "print('Kmeans Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the Kmeans model is:\\n', classification_report(labels, labels_predictions, zero_division=0))\n",
    "\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Kmeans Clusters')\n",
    "plt.scatter(train_data['HR'], train_data['HRV'], c=train_data['stress_pred_kmeans'].map({'low': 0, 'medium': 1, 'high': 2}), s=5)\n",
    "plt.xlabel('HR')\n",
    "plt.ylabel('HRV')\n",
    "plt.colorbar(ticks=[0, 1, 2], label='Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6d3a0",
   "metadata": {},
   "source": [
    "## Machine Learning Approach (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37799156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features and labels for the Random Forest Classifier\n",
    "X = train_data[['HR', 'HRV']]\n",
    "y = train_data['condition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create the Random Forest Classifier model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions of the Random Forest Classifier\n",
    "train_data['stress_pred_rf'] = clf.predict(X)\n",
    "labels_predictions = train_data['stress_pred_rf']\n",
    "\n",
    "print('The classification report matrix of the train data for the Random Forest Classifier is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f07f63",
   "metadata": {},
   "source": [
    "## Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering and Scaling\n",
    "num_classes = 3\n",
    "features = train_data[['HR', 'HRV']]\n",
    "labels   = train_data['condition'].map({'low': 0, 'medium': 1, 'high': 2})\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Create the train/test split\n",
    "features_train, features_test, labels_train, labels_test= train_test_split(features, labels, test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function for early stopping in case we have a decrease in accuracy\n",
    "callback = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=True, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# Define a small learning rate for the optimizer\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "\n",
    "\n",
    "# Create the Deep Learning Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(features_train.shape[1],)))\n",
    "model.add(Dense(features_train.shape[1], activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history=model.fit(features_train, labels_train, validation_split=0.1, epochs=10, verbose=True, batch_size=256, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11030e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Visualization\n",
    "plt.plot(history.history['val_accuracy'],color='red',label='Validation')\n",
    "plt.plot(history.history['accuracy'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'],color='red',label='Validation')\n",
    "plt.plot(history.history['loss'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc305e56",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c3acf8",
   "metadata": {},
   "source": [
    "# Stress Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(data_path + '/Stress_predict/hrv.csv')\n",
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37712aa7",
   "metadata": {},
   "source": [
    "## Threshold-Based Rule Engine Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf910b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions of the rule-based model and encode the labels to get the accuracy of this approach\n",
    "data['stress_pred_rule'] = data.apply(lambda row: classify_stress_threshold(row['HRV'], row['HR']), axis=1)\n",
    "labels = data['Label'].map({0: 'low', 1: 'high'})\n",
    "labels_predictions = data['stress_pred_rule']\n",
    "\n",
    "\n",
    "print('Threshold-Based Rule Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the threshold-based rule is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680dfc3",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Approach (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kmeans model with 3 clusters for the 3 classes [low, medium, high]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(data[['HRV', 'HR']])\n",
    "data['stress_pred_kmeans'] = kmeans.predict(data[['HRV', 'HR']])\n",
    "\n",
    "# Map the cluster labels to the stress levels\n",
    "cluster_mapping = {0: 'low', 1: 'medium', 2: 'high'}\n",
    "data['stress_pred_kmeans'] = data['stress_pred_kmeans'].map(cluster_mapping)\n",
    "\n",
    "# Get the predictions of the Kmeans model and encode the labels to get the accuracy of this approach\n",
    "labels_predictions = data['stress_pred_kmeans']\n",
    "\n",
    "print('Kmeans Accuracy:', accuracy_score(labels, labels_predictions))\n",
    "print('The classification report matrix of the Kmeans model is:\\n', classification_report(labels, labels_predictions, zero_division=0))\n",
    "\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Kmeans Clusters')\n",
    "plt.scatter(data['HR'], data['HRV'], c=data['stress_pred_kmeans'].map({'low': 0, 'medium': 1, 'high': 2}), s=5)\n",
    "plt.xlabel('HR')\n",
    "plt.ylabel('HRV')\n",
    "plt.colorbar(ticks=[0, 1, 2], label='Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd63e15",
   "metadata": {},
   "source": [
    "## Machine Learning Approach (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37005408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features and labels for the Random Forest Classifier\n",
    "X = data[['HR', 'HRV']]\n",
    "y = data['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create the Random Forest Classifier model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions of the Random Forest Classifier\n",
    "data['stress_pred_rf'] = clf.predict(X)\n",
    "labels_predictions = data['stress_pred_rf'].map({0: 'low', 1: 'high'})\n",
    "\n",
    "print('The classification report matrix of the train data for the Random Forest Classifier is:\\n', classification_report(labels, labels_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fa6f2",
   "metadata": {},
   "source": [
    "## Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a229fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering and Scaling\n",
    "num_classes = 2\n",
    "features = data[['HR', 'HRV']]\n",
    "labels   = data['Label']\n",
    "\n",
    "# Create the train/test split\n",
    "features_train, features_test, labels_train, labels_test= train_test_split(features, labels, test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function for early stopping in case we have a decrease in accuracy\n",
    "callback = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=True, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# Define a small learning rate for the optimizer\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "\n",
    "\n",
    "# Create the Deep Learning Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(features_train.shape[1],)))\n",
    "model.add(Dense(features_train.shape[1], activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79140287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history=model.fit(features_train, labels_train, validation_split=0.1, epochs=10, verbose=True, batch_size=256, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Visualization\n",
    "plt.plot(history.history['val_accuracy'],color='red',label='Validation')\n",
    "plt.plot(history.history['accuracy'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'],color='red',label='Validation')\n",
    "plt.plot(history.history['loss'],color='blue',label='Training')\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.xlabel('Epochs')    \n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
